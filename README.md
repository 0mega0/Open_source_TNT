# Open_source_TNT
## 2019开源课课设 TNT组
### 项目许可证

Apache License 2.0

### 项目人员和分工

指导老师：马奎

策划组长：俞昊洋 

模型建立与数据训练：周元媛  徐祯

数据搜集与整理：李彤 刘佳 石家琦 姜雨杉 张春阳

### 项目描述

#### MNIST 手写数字识别
MNIST数据集是NIST数据集的一个较小子集，有60000个训练数据和10000个测试数据，数据内容是28x28像素的图片，但是经过黑白处理转换成了0到255的灰度值。通过对给出的图片矩阵进行预测，得出与之相应的数字结果。

##### 模型建立
  我们组建立了一个拥有一个线性层的softmax回归模型来实现MNIST手写数字识别。
  
  softmax回归模型在于它的简洁，仅用一行代码就可以定义模型。
  
  softmax回归模型写成最紧凑的方式：
    
    y = softmax(Wx + b)
      
  softmax回归模型原理：
  MNIST数据集里面的每张图片都包含28x28像素，可以用数组来表示出每个像素点；把这个数组展开成向量，长度是28x28  784。对于softmax回归，为了得到一张给定图片属于某个特定数字类的证据，我们对图片像素值进行加权求和。如果这个像素具有很强的证据说明这张图片不属于该类，那么相应的权值为负数，相反如果这个像素拥有有利的证据支持这张图片属于这个类，那么权值是正数。
  softmax模型函数把输入值当成幂指数求值，再正则化这些结果值。这个幂运算表示，更大的证据对应更大的假设模型里面的乘数权重值。反之，拥有更少的证据意味着在假设模型里面拥有更小的乘数系数。假设模型里的权值不可以是0值或者负值。Softmax然后会正则化这些权重值，使它们的总和等于1，以此构造一个有效的概率分布。
  
##### 模型训练和损失评估
  我们使TensorFlow用梯度下降算法以0.01的学习速率最小化交叉熵，不断减少损失。
  我们让模型循环训练了1000次，每次随即抓取了训练数据中的100个批处理数据点，来减少我们的计算开销并同时最大化地学习到数据集的总体特征。我们将模型预测到的标签值和图片自带的标签值进行比对，如果匹配返回1，否则返回0；将这组布尔值转换成浮点数并取平均值，就得出了我们正确预测项的比例，最终的正确率可以达到91%。

### 项目开发流程
  我们组同时学习了git的使用方法，并分成两组，一组人学习了tensorflow的使用方法，建立模型并训练数据；而另一组人负责搜集项目相关的资料和数据；最后将全部代码和项目可视化结果图陆续push到github仓库中并编写readme和实验报告。
  
