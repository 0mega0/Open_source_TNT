# Open_source_TNT
## 2019开源课课设 TNT组

### LICENSE

Apache License 2.0


### INSTALL
配置、编译和安装该项目的说明信息，请在此填写，并填写到代码仓库中的对应文件。
 
本模型的运行环境为python3.7
在确定配置好环境后，将.py文件导入任意可执行python文件的IDE，编译后运行即可。




### CREDITS

指导老师：马奎

策划组长：俞昊洋 

模型建立与数据训练：周元媛  徐祯

数据搜集与整理：李彤 刘佳 石家琦 姜雨杉 张春阳


### 项目描述

#### MNIST 手写数字识别
MNIST数据集是NIST数据集的一个较小子集，有60000个训练数据和10000个测试数据，数据内容是28x28像素的图片，但是经过黑白处理转换成了0到255的灰度值。通过对给出的图片矩阵进行预测，得出与之相应的数字结果。

##### 模型建立
  我们组建立了一个拥有一个线性层的softmax回归模型来实现MNIST手写数字识别。
  
  softmax回归模型在于它的简洁，仅用一行代码就可以定义模型。
  
  softmax回归模型写成最紧凑的方式：
    
    y = softmax(Wx + b)
      
  softmax回归模型原理：
  MNIST数据集里面的每张图片都包含28x28像素，可以用数组来表示出每个像素点；把这个数组展开成向量，长度是28x28  784。对于softmax回归，为了得到一张给定图片属于某个特定数字类的证据，我们对图片像素值进行加权求和。如果这个像素具有很强的证据说明这张图片不属于该类，那么相应的权值为负数，相反如果这个像素拥有有利的证据支持这张图片属于这个类，那么权值是正数。
  softmax模型函数把输入值当成幂指数求值，再正则化这些结果值。这个幂运算表示，更大的证据对应更大的假设模型里面的乘数权重值。反之，拥有更少的证据意味着在假设模型里面拥有更小的乘数系数。假设模型里的权值不可以是0值或者负值。Softmax然后会正则化这些权重值，使它们的总和等于1，以此构造一个有效的概率分布。
  
##### 模型训练和损失评估
  我们使TensorFlow用梯度下降算法以0.01的学习速率最小化交叉熵，不断减少损失。
  我们让模型循环训练了1000次，每次随即抓取了训练数据中的100个批处理数据点，来减少我们的计算开销并同时最大化地学习到数据集的总体特征。我们将模型预测到的标签值和图片自带的标签值进行比对，如果匹配返回1，否则返回0；将这组布尔值转换成浮点数并取平均值，就得出了我们正确预测项的比例，最终的正确率可以达到91%。

### 项目开发流程
  我们组同时学习了git的使用方法，并分成两组，一组人学习了tensorflow的使用方法，建立模型并训练数据；而另一组人负责搜集项目相关的资料和数据；最后将全部代码和项目可视化结果图陆续push到github仓库中并编写readme和实验报告。
  
### FAQ
Q: MNIST数据集里都有些什么？
A：数据集被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）；每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。

Q：为什么要使用tensorflow来实现模型？
A：为了用python实现高效的数值计算，我们通常会使用函数库，比如NumPy，会把类似矩阵乘法这样的复杂运算使用其他外部语言实现。不幸的是，从外部计算切换回Python的每一个操作，仍然是一个很大的开销。如果你用GPU来进行外部计算，这样的开销会更大。用分布式的计算方式，也会花费更多的资源用来传输数据。TensorFlow也把复杂的计算放在python之外完成，但是为了避免前面说的那些开销，它做了进一步完善。Tensorflow不单独地运行单一的复杂计算，而是让我们可以先用图描述一系列可交互的计算操作，然后全部一起在Python之外运行。
Q：如何训练这个模型？
A：随机梯度下降训练（使用一小部分的随机数据来进行训练）。在理想情况下，我们希望用我们所有的数据来进行每一步的训练，因为这能给我们更好的训练结果，但显然这需要很大的计算开销。所以，每一次训练我们可以使用不同的数据子集，这样做既可以减少计算开销，又可以最大化地学习到数据集的总体特性。


  
